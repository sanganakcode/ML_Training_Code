{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_DEB25BmXETO","executionInfo":{"status":"ok","timestamp":1691668916830,"user_tz":420,"elapsed":3448,"user":{"displayName":"Immanuel Kant","userId":"05198496277802312927"}}},"outputs":[],"source":["# Python Project Template\n","# Remember to df.to_csv(\"periodic_backup.csv\")   OFTEN!!!\n","# df.to_csv(\"auto_data_uk.csv\")\n","\n","# 1. Prepare Problem\n","# a) Load libraries\n","import pandas as pd\n","import numpy as np\n","import scipy.stats as stats\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","%matplotlib inline\n","# b) Load dataset\n","# Data Dictionary: https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset\n","df = pd.read_csv(\"https://raw.githubusercontent.com/fenago/introml/main/Life%20Expectancy%20Data.csv\")\n","\n","# df = pd.read_csv(\"https://raw.githubusercontent.com/fenago/datasets/main/UCI_Credit_Card.csv\")\n","# adult_census = pd.read_csv(\"https://github.com/fenago/MLEssentials2/blob/main/datasets/adult-census.csv?raw=true\")\n","\n","# Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n"]},{"cell_type":"code","source":["shark_tank = pd.read_csv(\"https://raw.githubusercontent.com/fenago/datasets/main/SharkTank-Final.csv\")\n","shark_tank.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525},"id":"y9ITC3d4CZmL","outputId":"13e576d5-1340-42a3-ca30-ff46afd907f8","executionInfo":{"status":"ok","timestamp":1690555749095,"user_tz":420,"elapsed":520,"user":{"displayName":"Immanuel Kant","userId":"05198496277802312927"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Season  Episode             Company   \\\n","0       1        1  BluePine Industries   \n","1       1        1        Booz scooters   \n","2       1        1  Heart up my Sleeves   \n","3       1        2           Tagz Foods   \n","4       1        2       Head and Heart   \n","\n","                                            Idea  Deal   Receive_Offer  \\\n","0                                   Frozen Momos      1              1   \n","1  Renting e-bike for mobility in private spaces      1              1   \n","2                             Detachable Sleeves      1              1   \n","3                           Healthy Potato Chips      1              1   \n","4                       Brain Development Course      0              0   \n","\n","   Reject_Offer  Number of presenters  No of male presenters  \\\n","0           0.0                     3                      2   \n","1           0.0                     1                      1   \n","2           0.0                     1                      0   \n","3           0.0                     2                      2   \n","4           NaN                     4                      1   \n","\n","   No of female presenters  ...  AshneerGrover_deal  AnupamMittal_deal  \\\n","0                        1  ...                   1                  0   \n","1                        0  ...                   1                  0   \n","2                        1  ...                   0                  1   \n","3                        0  ...                   1                  0   \n","4                        3  ...                   0                  0   \n","\n","   AmanGupta_deal  NamitaThapar_deal  VineetaSingh_deal  PeyushBansal_deal  \\\n","0               1                  0                  1                  0   \n","1               0                  0                  1                  0   \n","2               0                  0                  1                  0   \n","3               0                  0                  0                  0   \n","4               0                  0                  0                  0   \n","\n","   GhazalAlagh_deal  Number of Sharks invested  Amount per Shark   \\\n","0                 0                          3               25.0   \n","1                 0                          2               20.0   \n","2                 0                          2               12.5   \n","3                 0                          1               70.0   \n","4                 0                          0                0.0   \n","\n","   Equity per Shark  \n","0          5.333333  \n","1         25.000000  \n","2         15.000000  \n","3          2.750000  \n","4          0.000000  \n","\n","[5 rows x 33 columns]"],"text/html":["\n","\n","  <div id=\"df-3301527a-10c2-49a2-9898-a3bccce900e6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Season</th>\n","      <th>Episode</th>\n","      <th>Company</th>\n","      <th>Idea</th>\n","      <th>Deal</th>\n","      <th>Receive_Offer</th>\n","      <th>Reject_Offer</th>\n","      <th>Number of presenters</th>\n","      <th>No of male presenters</th>\n","      <th>No of female presenters</th>\n","      <th>...</th>\n","      <th>AshneerGrover_deal</th>\n","      <th>AnupamMittal_deal</th>\n","      <th>AmanGupta_deal</th>\n","      <th>NamitaThapar_deal</th>\n","      <th>VineetaSingh_deal</th>\n","      <th>PeyushBansal_deal</th>\n","      <th>GhazalAlagh_deal</th>\n","      <th>Number of Sharks invested</th>\n","      <th>Amount per Shark</th>\n","      <th>Equity per Shark</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>BluePine Industries</td>\n","      <td>Frozen Momos</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>25.0</td>\n","      <td>5.333333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Booz scooters</td>\n","      <td>Renting e-bike for mobility in private spaces</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>20.0</td>\n","      <td>25.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Heart up my Sleeves</td>\n","      <td>Detachable Sleeves</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>12.5</td>\n","      <td>15.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Tagz Foods</td>\n","      <td>Healthy Potato Chips</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>70.0</td>\n","      <td>2.750000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Head and Heart</td>\n","      <td>Brain Development Course</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 33 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3301527a-10c2-49a2-9898-a3bccce900e6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-d225570e-981b-478b-a375-1197f3c6524c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d225570e-981b-478b-a375-1197f3c6524c')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-d225570e-981b-478b-a375-1197f3c6524c button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3301527a-10c2-49a2-9898-a3bccce900e6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3301527a-10c2-49a2-9898-a3bccce900e6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","import certifi\n","from sklearn.datasets import fetch_openml\n","# Download the dataset from openml\n","dataset = fetch_openml(data_id=42803, as_frame=True)\n","#Extract feature matrix X and show 5 random samples\n","df = dataset[\"frame\"]\n","df.sample(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWkgn4aWaWSx","outputId":"0c100909-06f6-4714-baf8-63f61ca4d282"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}]},{"cell_type":"code","source":["# Set the Environment\n","# Ignore Warnings\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","#Write out the versions of all packages to requirements.txt\n","!pip freeze >> requirements.txt\n","\n","# Remove the restriction on Jupyter that limits the columns displayed (the ... in the middle)\n","# pd.set_option('max_columns',None)\n","# Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html#\n","\n","# Pretty Display of variables.  for instance, you can call df.head() and df.tail() in the same cell and BOTH display w/o print\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","# List of ALL Magic Commands.  To run a magic command %var  --- i.e.:  %env\n","%lsmagic\n","# %env  -- list environment variables\n","# %%time  -- gives you information about how long a cel took to run\n","# %%timeit -- runs a cell 100,000 times and then gives you the average time the cell will take to run (can be LONG)\n","# %pdb -- python debugger\n","\n","# to display nice model diagram\n","from sklearn import set_config\n","set_config(display='diagram')\n","\n","# Python ≥3.5 is required\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# Scikit-Learn ≥0.20 is required\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","print(\"\\n Numpy: \" + np.__version__)\n","print(\"\\n sklearn: \" + sklearn.__version__)"],"metadata":{"id":"_MQpj7aaeqSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. structural analysis of the data\n","# a) basic data queries\n","%time\n","df.sample(5)"],"metadata":{"id":"pTr_EShtflCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%timeit\n","# Show size of the dataset\n","print(\"Rows and Columns: \\n\", df.shape, \"\\n\")\n","print(\"General Information: \\n\", df.info(), \"\\n\")\n","# b) Validate and change all data types\n","print(df.dtypes)"],"metadata":{"id":"2lLu5Kd8gKXp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# IMPORTANT:  Change data types to the correct data types\n","# EXAMPLE of one but you may have to repeat this process\n","# Change data type of 'sex_of_Driver'\n","# df['measles_'] = df['measles_'].astype('int64')\n","# df[\"cubicinches\"]=pd.to_numeric(df[\"cubicinches\"], errors='coerce')\n","# df[\"weightlbs\"]=pd.to_numeric(df[\"weightlbs\"], errors='coerce')\n","df['Sex_of_Driver'] = df['Sex_of_Driver'].astype('float')\n","\n","# Even though Sex_of_Driver is a numerical or boolean feature, it somehow was stored as a categorical one. This is sometimes due to some typo in data recording. So let's take care of that."],"metadata":{"id":"JDZaEh2_hnPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Treat obviously incorrect values in your dataset\n","\n","# If you have values in your columns that you want to replace - use this for loop\n","# For instance - in the CreditScoring dataset - there are numerous 99999999 that need to be replaced\n","\n","# for c in ['income', 'assets', 'debt']:\n","#    df[c] = df[c].replace(to_replace=99999999, value=np.nan)"],"metadata":{"id":"dZ6HkWsPiPeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# If you want to remove a value from a column - use this:\n","# df = df[df.status != 'unk']   # This removes the value 'unk' from your data in the column.  Modify as needed"],"metadata":{"id":"vw_XQU02iZMj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# drop multiple columns by name\n","# df.drop(['column_name1', 'column_name2'], axis=1, inplace=True)"],"metadata":{"id":"2LlNVDtcii9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Count how many times each data type is present in the dataset\n","pd.value_counts(df.dtypes)"],"metadata":{"id":"wdTmCfd8iquZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How many unique values per feature\n","df.nunique().to_frame()"],"metadata":{"id":"gff6hfy0ixlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes.to_frame()"],"metadata":{"id":"LbUhpJxtjVni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# c) Split into Numeric List and Categorical List\n","# Split the data into numeric and categorical lists and dataframes\n","numerics = ['int16','int32','int64','float64']\n","catDF = df.select_dtypes(exclude=numerics)\n","numDF = df.select_dtypes(include=numerics)\n","catDF.head()\n","numDF.head()"],"metadata":{"id":"9KMIi9lgjYY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This is how you merge the datasets back together:\n","# Merge back into a single df\n","# preparing the X Variables  (Don't forget ot remove the target!!)\n","X = pd.concat([catDF,numDF],axis=1)\n","print(X.shape)\n","\n","# This is how you extract the target variable\n","# y = df_X['Sex_of_Driver']\n","# X.drop(['Sex_of_Driver'],axis=1,inplace=True)"],"metadata":{"id":"6ZUZGxeZlEVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display non-numerical features --> cat\n","df.select_dtypes(exclude=\"number\").head()"],"metadata":{"id":"oZN-0N3blcfx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display numerical features --> numeric features\n","df.select_dtypes(include=\"number\").head()"],"metadata":{"id":"E8aIao0mljtH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 3. Qualitative Investigation of the Data\n","# a) Duplicates\n","# Duplicates in the Columns?\n","df.duplicated()\n","df.duplicated().sum()\n","\n","# Duplicated Rows?\n","df[df.duplicated()]\n","# Find duplicates in specific columns from your dataset.  Replace with your columns obviously.  keep the first or last dupe.\n","# df.loc[df.duplicated(keep='last'), ['InvoiceNo', 'StockCode', 'InvoiceDate', 'CustomerID']]\n","\n","# Only consider duplicates in these columns and drop only them\n","# df.duplicated(subset=['InvoiceNo', 'StockCode', 'InvoiceDate','CustomerID'], keep='first').sum()\n","# By looking only at these four columns instead of all of them, we can see that the number of duplicate rows may increase/decrease\n","# This means that there are rows that have the exact same values as these four columns but have different values in\n","# other columns, which means they may be different records.\n","# In most cases, it is better to use all the columns to identify duplicate records.\n","\n","# df_unique = df.drop_duplicates(keep='first')\n","# df.drop_duplicates(keep='first')\n","\n","# Check number of duplicates while ignoring the index feature\n","n_duplicates = df.drop(labels=['Accident_Index'], axis=1).duplicated().sum()\n","\n","print(f\"You seem to have {n_duplicates} duplicates in your database.\")\n","\n","#  Extract column names of all features, except 'Accident_Index'\n","columns_to_consider = df.drop(labels=['Accident_Index'], axis=1).columns\n","\n","# Drop duplicates based on 'columns_to_consider'\n","df.drop_duplicates(subset=columns_to_consider, inplace=True)\n","df.shape"],"metadata":{"id":"T7lOjVylmClx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MISSING VALUES\n","df.isna()\n","df.isna().sum()\n","\n","# Check for missing values in a single column\n","# df[df['Description'].isna()]\n","\n","# List all rows that are missing a value in this field\n","# df.dropna(subset=['Description'])\n","\n","# Drop all rows that are missing a value in this field:\n","# df.dropna(subset=['Description'], inplace=True)\n","\n","# b) Missing Values per Sample (Big Holes)\n","\n","\n","plt.figure(figsize=(15, 8))\n","sns.set_style('whitegrid')\n","\n","g = sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n","# g = sns.heatmap(df_X.loc[df_X.isnull().sum(1).sort_values(ascending=1).index].isnull(), cbar=False, cmap='viridis')\n","g.set_xlabel('Column Number')\n","g.set_ylabel('Sample Number')"],"metadata":{"id":"zuPTCoLhnXCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install missingno\n","import missingno as msno\n","msno.matrix(df, labels=True, sort='descending', color=(0.27, 0.52, 1.0));"],"metadata":{"id":"fomqMC8-oAiP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make a decision... drop rows that are 20% or more empty (you set the threshhold)\n","df = df.dropna(thresh=df.shape[1] * 0.80, axis = 0).reset_index(drop=True)\n","df.shape"],"metadata":{"id":"TWVj0x8jpU1B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["msno.matrix(df, labels=True, sort='descending', color=(0.27, 0.52, 1.0));"],"metadata":{"id":"OKL2jxiUpn0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15, 8))\n","sns.set_style('whitegrid')\n","\n","g = sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n","# g = sns.heatmap(df_X.loc[df_X.isnull().sum(1).sort_values(ascending=1).index].isnull(), cbar=False, cmap='viridis')\n","g.set_xlabel('Column Number')\n","g.set_ylabel('Sample Number')"],"metadata":{"id":"G7T-6RriqC5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# c) Missing Values per Feature (Big Holes)\n","df.isna().mean().sort_values().plot(\n","    kind=\"bar\", figsize=(15, 4),\n","    title=\"Percentage of missing values per feature\",\n","    ylabel=\"Ratio of missing values per feature\");"],"metadata":{"id":"eihUaDTcq8jQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# drop any col that is more than 15% empty\n","df = df.dropna(thresh=df.shape[0] * 0.85,axis=1)\n","df.shape"],"metadata":{"id":"99xOYB2NrIOy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# c) Missing Values per Feature (Big Holes)\n","df.isna().mean().sort_values().plot(\n","    kind=\"bar\", figsize=(15, 4),\n","    title=\"Percentage of missing values per feature\",\n","    ylabel=\"Ratio of missing values per feature\");"],"metadata":{"id":"N-W6rk71rchf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15, 8))\n","sns.set_style('whitegrid')\n","\n","g = sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n","# g = sns.heatmap(df_X.loc[df_X.isnull().sum(1).sort_values(ascending=1).index].isnull(), cbar=False, cmap='viridis')\n","g.set_xlabel('Column Number')\n","g.set_ylabel('Sample Number')"],"metadata":{"id":"Q50EBIkqrlIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv(\"periodic_backup.csv\")"],"metadata":{"id":"rzAYa6Serz1A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# d) Impute Values (Small Holes)\n","# df['CustomerID'].fillna('Missing', inplace=True)\n","\n","# Replace NaN one column with the median\n","# df['col1'] = df['col1'].fillna(df['col1'].median())\n","# df = df.fillna(df.median())\n","\n","# to see categorical encoding - see:  https://github.com/fenago/eda/blob/main/Cars_XGBoost.ipynb"],"metadata":{"id":"oOS4KlWPsW2W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Content Investigation of the Data\n","# a) Distributions of data in each feature\n","# Plots the histogram for each numerical feature in a separate subplot\n","df.hist(bins=25, figsize=(15, 25), layout=(-1, 5), edgecolor=\"black\")\n","plt.tight_layout();"],"metadata":{"id":"A0XL4qHgsuj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# b) Patterns\n","# Creates mask to identify numerical features with more or less than 25 unique features\n","cols_continuous = df.select_dtypes(include=\"number\").nunique() >= 25\n","\n","# Create a new dataframe which only contains the continuous features\n","df_continuous = df[cols_continuous[cols_continuous].index]\n","df_continuous.shape\n","\n","sns.pairplot(df_continuous, height=1.5, plot_kws={\"s\": 2, \"alpha\": 0.2});\n"],"metadata":{"id":"RQZjNvVGt_Iw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a new dataframe which doesn't contain the numerical continuous features\n","df_discrete = df[cols_continuous[~cols_continuous].index]\n","df_discrete.shape"],"metadata":{"id":"aoT7t6G3vQNv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Relationships\n","# Evaluate but remember to consider multicollinearity\n","\n","# Computes feature correlation\n","df_corr = df.corr(method=\"spearman\") # pearson assumes a linear relationship... spearman does not\n","\n","# Create labels for the correlation matrix\n","labels = np.where(np.abs(df_corr)>0.75, \"S\",\n","                  np.where(np.abs(df_corr)>0.5, \"M\",\n","                           np.where(np.abs(df_corr)>0.25, \"W\", \"\")))\n","\n","# Plot correlation matrix\n","plt.figure(figsize=(15, 15))\n","sns.heatmap(df_corr, mask=np.eye(len(df_corr)), square=True,\n","            center=0, annot=labels, fmt='', linewidths=.5,\n","            cmap=\"vlag\", cbar_kws={\"shrink\": 0.8});"],"metadata":{"id":"JyDPu3cNvZI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  Creates a mask to remove the diagonal and the upper triangle.\n","lower_triangle_mask = np.tril(np.ones(df_corr.shape), k=-1).astype(\"bool\")\n","\n","#  Stack all correlations, after applying the mask\n","df_corr_stacked = df_corr.where(lower_triangle_mask).stack().sort_values()\n","\n","#  Showing the lowest and highest correlations in the correlation matrix\n","display(df_corr_stacked)"],"metadata":{"id":"WSHhk2_rwgBQ"},"execution_count":null,"outputs":[]}]}